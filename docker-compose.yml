services:
  backend:
    build:
      context: backend
      dockerfile: docker/Dockerfile
    init: true
    volumes:
      - ./backend:/app
      - backend-_build:/app/_build
      - backend-deps:/app/deps
    command:
      - /app/docker/compose_command.sh
    depends_on:
      - postgres
      - mongo
    ports:
      - 4000:4000
    environment:
      POSTGRES_HOSTNAME: postgres
      POSTGRES_EVENT_STORE_DB: backend_es
      # POSTGRES_ECTO_DB: backend_ecto
      MONGO_HOSTNAME: mongo
      MONGO_DATABASE: backend

  frontend:
    build:
      context: frontend
      dockerfile: docker/Dockerfile
    init: true
    volumes:
      - ./frontend:/app
      - frontend-node_modules:/app/node_modules
    command:
      - /app/docker/compose_command.sh
    depends_on:
      - backend
    ports:
      - 3000:3000

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      PGDATA: /var/lib/postgresql/data

  mongo:
    image: mongo:latest
    command: [ "--bind_ip_all", "--replSet", "rs0" ]
    depends_on:
      - mongo_rs_init_on_countdown

  mongo_rs_init_on_countdown:
    image: mongo:latest
    command: >
      sh -c "sleep 10 && mongosh --host mongo:27017 --eval 'config = { _id: \"rs0\", \"members\": [{ _id: 0, host: \"mongo\" }]}; try{db.adminCommand({ replSetGetStatus: 1 })}catch(e){rs.initiate(config)}'"

volumes:
# I'm forced to use named volumes because of how I "docker-compose run" into containers to run dev commands (yarn add, mix deps.get, ...)
# If I used anonymous volumes, imperatively entered containers (dc run) do not share the anonymous volume (I consider this a docker-compose bug)
# I follow the anonymous volume convention:
# {service}-{directory_name}
  frontend-node_modules:
  backend-_build:
  backend-deps:
